{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Web Scraping with Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Home\n",
      "  </h1>\n",
      "  <p>\n",
      "   Wow!\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "html = \"<html><head></head><body><h1>Home</h1><p>Wow!</p></body></html>\"\n",
    "    # html이 가장 바깥, 시작과 끝\n",
    "    # head는 사용자에게 보여주지는 않지만 페이지를 구현하는데 필요한 정보\n",
    "    # body는 사용자에게 보여주는 정보\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # \"html.parser\"를 넣는 이유는 어떤 parser로 parsing할지를 지정하는 것.\n",
    "soup.prettify()\n",
    "print(soup.prettify())\n",
    "    # prettify는 예쁘게 위아래로 나열하고, 필요한 곳은 들여쓰기하게 만드는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rotten Tomatoes에서 scraping해오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"movie_list\" id=\"Top-Box-Office\">\n",
      "<tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/the_hitmans_bodyguard\">\n",
      "<span class=\"icon tiny rotten\"></span>\n",
      "<span class=\"tMeterScore\">39%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/the_hitmans_bodyguard\">The Hitman's Bodyguard</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/the_hitmans_bodyguard\">\n",
      "                    $21.4M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/annabelle_creation\">\n",
      "<span class=\"icon tiny fresh\"></span>\n",
      "<span class=\"tMeterScore\">67%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/annabelle_creation\">Annabelle: Creation</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/annabelle_creation\">\n",
      "                    $15.7M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/logan_lucky\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">94%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/logan_lucky\">Logan Lucky</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/logan_lucky\">\n",
      "                    $7.7M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/dunkirk_2017\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">93%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/dunkirk_2017\">Dunkirk</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/dunkirk_2017\">\n",
      "                    $6.7M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/the_nut_job_2_nutty_by_nature\">\n",
      "<span class=\"icon tiny rotten\"></span>\n",
      "<span class=\"tMeterScore\">11%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/the_nut_job_2_nutty_by_nature\">The Nut Job 2: Nutty by Nature</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/the_nut_job_2_nutty_by_nature\">\n",
      "                    $5.1M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/the_emoji_movie\">\n",
      "<span class=\"icon tiny rotten\"></span>\n",
      "<span class=\"tMeterScore\">8%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/the_emoji_movie\">The Emoji Movie</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/the_emoji_movie\">\n",
      "                    $4.5M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/spider_man_homecoming\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">92%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/spider_man_homecoming\">Spider-Man: Homecoming</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/spider_man_homecoming\">\n",
      "                    $4.3M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/girls_trip\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">88%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/girls_trip\">Girls Trip</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/girls_trip\">\n",
      "                    $4M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/the_dark_tower_2017\">\n",
      "<span class=\"icon tiny rotten\"></span>\n",
      "<span class=\"tMeterScore\">16%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/the_dark_tower_2017\">The Dark Tower</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/the_dark_tower_2017\">\n",
      "                    $3.8M</a>\n",
      "</td>\n",
      "</tr><tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/wind_river_2017\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">86%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/wind_river_2017\">Wind River</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/wind_river_2017\">\n",
      "                    $3M</a>\n",
      "</td>\n",
      "</tr></table>\n"
     ]
    }
   ],
   "source": [
    "# Scraping Part\n",
    "url = \"https://www.rottentomatoes.com/\"\n",
    "\n",
    "html = urllib.request.urlopen(url)\n",
    "    # html을 print하면 <http.client.HTTPResponse object at 0x0000016E85B27C18>이 나온다.\n",
    "        # 이 형태로는 사용할 수 없고 read()해서 html코드 형태로 바꿔야 한다\n",
    "source = html.read()\n",
    "    # source를 바로 print하면 bytecode 형태로 나온다\n",
    "html.close()\n",
    "\n",
    "# Parsing Part\n",
    "soup = BeautifulSoup(source, \"html.parser\")\n",
    "    # html.parser를 이용하여 bytecode를 html code로 바꾼다\n",
    "table = soup.find(id=\"Top-Box-Office\")\n",
    "    # find : soup이라는 html code에서 id가 Top-Box-Office인 것을 찾으라는 뜻.\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/the_hitmans_bodyguard\">\n",
      "<span class=\"icon tiny rotten\"></span>\n",
      "<span class=\"tMeterScore\">39%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/the_hitmans_bodyguard\">The Hitman's Bodyguard</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/the_hitmans_bodyguard\">\n",
      "                    $21.4M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/annabelle_creation\">\n",
      "<span class=\"icon tiny fresh\"></span>\n",
      "<span class=\"tMeterScore\">67%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/annabelle_creation\">Annabelle: Creation</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/annabelle_creation\">\n",
      "                    $15.7M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/logan_lucky\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">94%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/logan_lucky\">Logan Lucky</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/logan_lucky\">\n",
      "                    $7.7M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/dunkirk_2017\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">93%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/dunkirk_2017\">Dunkirk</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/dunkirk_2017\">\n",
      "                    $6.7M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/the_nut_job_2_nutty_by_nature\">\n",
      "<span class=\"icon tiny rotten\"></span>\n",
      "<span class=\"tMeterScore\">11%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/the_nut_job_2_nutty_by_nature\">The Nut Job 2: Nutty by Nature</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/the_nut_job_2_nutty_by_nature\">\n",
      "                    $5.1M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/the_emoji_movie\">\n",
      "<span class=\"icon tiny rotten\"></span>\n",
      "<span class=\"tMeterScore\">8%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/the_emoji_movie\">The Emoji Movie</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/the_emoji_movie\">\n",
      "                    $4.5M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/spider_man_homecoming\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">92%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/spider_man_homecoming\">Spider-Man: Homecoming</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/spider_man_homecoming\">\n",
      "                    $4.3M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/girls_trip\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">88%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/girls_trip\">Girls Trip</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/girls_trip\">\n",
      "                    $4M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/the_dark_tower_2017\">\n",
      "<span class=\"icon tiny rotten\"></span>\n",
      "<span class=\"tMeterScore\">16%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/the_dark_tower_2017\">The Dark Tower</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/the_dark_tower_2017\">\n",
      "                    $3.8M</a>\n",
      "</td>\n",
      "</tr>, <tr class=\"\">\n",
      "<td class=\"left_col\">\n",
      "<a href=\"/m/wind_river_2017\">\n",
      "<span class=\"icon tiny certified_fresh\"></span>\n",
      "<span class=\"tMeterScore\">86%</span>\n",
      "</a>\n",
      "</td>\n",
      "<td class=\"middle_col\">\n",
      "<a href=\"/m/wind_river_2017\">Wind River</a>\n",
      "</td>\n",
      "<td class=\"right_col right\">\n",
      "<a href=\"/m/wind_river_2017\">\n",
      "                    $3M</a>\n",
      "</td>\n",
      "</tr>]\n"
     ]
    }
   ],
   "source": [
    "# \"Top-Box-Office\"의 정보를 다시 한 단계 작게, (table row)로 분할한다.\n",
    "    # tr은 수평 한 줄, td는 한 줄 안의 각 세로 줄의 정보\n",
    "\n",
    "all_tr = table.find_all(\"tr\")\n",
    "    # find()를 하면 처음부터 검색을 하는데, 처음으로 발견하는 것을 반환하고 끝난다.\n",
    "        # find_all()을 하면 처음부터 끝까지 검색하며 해당하는 값을 모두 list형태로 반환한다.\n",
    "print(all_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39 The Hitman's Bodyguard 21.4M\n",
      "0.67 Annabelle: Creation 15.7M\n",
      "0.94 Logan Lucky 7.7M\n",
      "0.93 Dunkirk 6.7M\n",
      "0.11 The Nut Job 2: Nutty by Nature 5.1M\n",
      "0.8 The Emoji Movie 4.5M\n",
      "0.92 Spider-Man: Homecoming 4.3M\n",
      "0.88 Girls Trip 4M\n",
      "0.16 The Dark Tower 3.8M\n",
      "0.86 Wind River 3M\n"
     ]
    }
   ],
   "source": [
    "# tr의 정보를 다시 한 단계 작게, td (table data)로 분할한다.\n",
    "all_tr = table.find_all(\"tr\")\n",
    "for tr in all_tr:\n",
    "    all_td = tr.find_all(\"td\")\n",
    "    score = all_td[0].find(\"span\", attrs={\"class\":\"tMeterScore\"}).text.strip(\"%\")\n",
    "        # 특정 A : B 속성을 가진 span을 찾으라는 뜻\n",
    "            # span이 두 개이기 때문에\n",
    "        # \".text\"를 해야지 span tag 안에 있는 text를 추출해낸다. 하지 않으면 span tag만 출력된다.\n",
    "    movie_name = all_td[1].a.text\n",
    "    amount = all_td[2].a.text.strip().strip(\"$\")\n",
    "        # movie_name & amount는 td 아래 정보가 하나 밖에 없기에\n",
    "        # amount가 다른 줄에 찍히는 이유는 원문에서 값 앞에 공백을 놔뒀기 때문이다\n",
    "            # 해결하기위해 strip()을 사용한다. 만약 () 안에 아무것도 없으면, 공백을 없애라는 뜻\n",
    "                # strip() 쓰는 것이 replace()하는 것보다 간단하다.\n",
    "                \n",
    "    print(\"0.\" + score, movie_name, amount)\n",
    "        # 원문에서 percentage로 나타나던 숫자에서, \"%\"을 strip하고 print하는 단계에서 앞에 \"0.\"을 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naver에서 eclipse를 블로그 검색하여, 첫 페이지의 제목이랑 링크를 scraping해오기\n",
    "    # 어떻게 링크를 가져올지가 핵심"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n",
      "None None\n",
      "None None\n",
      "None None\n",
      "None None\n",
      "None None\n",
      "None None\n",
      "None None\n",
      "None None\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "# My attempt to do this exercise\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Scraping Part\n",
    "url = \"https://search.naver.com/search.naver?where=post&query=eclipse\"\n",
    "html = urllib.request.urlopen(url)\n",
    "source = html.read()\n",
    "html.close()\n",
    "\n",
    "# Parsing Part\n",
    "soup = BeautifulSoup(source, \"html.parser\")\n",
    "table = soup.find(id=\"elThumbnailResultArea\")\n",
    "\n",
    "all_dt = table.find_all(\"dt\")\n",
    "for dt in all_dt:\n",
    "    all_td = dt.a\n",
    "    link = all_td.find(attrs = {\"class\"})\n",
    "    title = all_td.find(attrs = {\"title\"})\n",
    "                \n",
    "    print(link, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the QUERY: eclipse\n",
      "http://blog.naver.com/woozaaya?Redirect=Log&logNo=221079209124 \n",
      " 미국에서 개기일식을 보다! Eclipse 2017\n",
      "http://blog.naver.com/xcxvnnm34?Redirect=Log&logNo=221079948668 \n",
      " 170822 엑소 A MESSAGE FROM EXO PLANET : TOTAL ECLIPSE 영상 (+해석)\n",
      "http://blog.naver.com/puretearing?Redirect=Log&logNo=221079231032 \n",
      " 미국 개기일식 (이클립스: Eclipse) 으로 축제처럼 맞이한 월요일에.\n",
      "http://blog.naver.com/kzio1004?Redirect=Log&logNo=221078586248 \n",
      " Solar eclipse\n",
      "http://blog.naver.com/chanelyun?Redirect=Log&logNo=221079340556 \n",
      " [아쉬탕가]re-start(Full Moon Day)\"100년만의 Eclipse\"\n",
      "http://blog.naver.com/calloline_?Redirect=Log&logNo=221080209727 \n",
      " 신혼일기 #08 - Solar Eclipse\n",
      "http://blog.naver.com/jjhk282?Redirect=Log&logNo=221079593619 \n",
      " Total Solar eclipse in California\n",
      "http://blog.naver.com/storylineco?Redirect=Log&logNo=221080732596 \n",
      " 개기 일식: Total Solar Eclipse\n",
      "http://blog.naver.com/ryanian?Redirect=Log&logNo=221080914726 \n",
      " [밴쿠버 일상] 일식(solar eclipse) 보셨나요???!!!\n",
      "http://blog.naver.com/nyhotpoint?Redirect=Log&logNo=221079226835 \n",
      " 뉴욕이클립스Eclipse/개기일식2017\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Scraping Part\n",
    "query = input(\"Enter the QUERY: \")\n",
    "url = \"https://search.naver.com/search.naver?where=post&query=%s\" % query\n",
    "html = urllib.request.urlopen(url)\n",
    "source = html.read()\n",
    "html.close()\n",
    "\n",
    "# Parsing Part\n",
    "    # 1. Conversion to html\n",
    "soup = BeautifulSoup(source, \"html.parser\")\n",
    "result_list = soup.find(id=\"elThumbnailResultArea\")\n",
    "\n",
    "    # 2. Actual analysis of the page\n",
    "all_li = result_list.find_all(\"li\")\n",
    "\n",
    "for li in all_li:\n",
    "    dt = li.find(\"dt\")\n",
    "    link = dt.a['href']\n",
    "        # 위 두 줄을 압축하여 \"dt = li.dt.a['href]\"도 가능\n",
    "    title = dt.a['title']\n",
    "    \n",
    "    print(link, \"\\n\", title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are enough to cover most actions the user may order with selenium\n",
    "\n",
    "import os\n",
    "    # os is the Windows OS itself, because things like \"click()\" use the hardware,\n",
    "        # which is controlled by the os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff_driver = webdriver.Chrome()\n",
    "    # ff_driver is just a variable's name, ff because the instructor is using Firefox's webdriver\n",
    "ff_driver.get(\"https://www.google.co.kr/\")\n",
    "\n",
    "# Find by ID\n",
    "query = ff_driver.find_element_by_id(\"lst-ib\")\n",
    "query.send_keys(\"linus torvalds nvidia\")\n",
    "\n",
    "# Find by Name\n",
    "ff_driver.find_element_by_name(\"btnK\").click()\n",
    "    # id & name의 차이는 주민등록번호와 사람 이름의 차이\n",
    "        # id는 항상 unique, name은 겹칠 수도 있고 아닐 수도 있고\n",
    "ff_driver.implicitly_wait(10)\n",
    "    # 컴퓨터 성능이나 인터넷 연결에 따라 로딩하는데 시간이 걸릴 수 있다.\n",
    "        # 로딩을 하지 않았는데 실행하면 문제날 수 있으니까 implicitly_wait()을 넣는다\n",
    "            # implicitly_wait()에는 몇 초를 기다릴지를 정해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linus Torvalds - Nvidia F_ck You! - YouTube\n",
      "Linus Torvalds: Nvidia, Fuck You! - YouTube\n",
      "Nvidia Responds to F-Bomb From Linus Torvalds | WIRED\n",
      "Linus Torvalds Gives Nvidia the Finger. Literally | WIRED\n",
      "linus torvalds nvidia 관련 이미지\n",
      "It's Been Three Years Since Linus Torvalds' Huge NVIDIA Rant ...\n",
      "Linus Torvalds says “f–k you” to NVIDIA | Ars Technica\n",
      "Nvidia seeks peace with Linux, pledges help on open source driver ...\n",
      "Torvalds gives Nvidia software thumbs up, not middle finger - CNET\n",
      "Why did Linus Torvalds give a middle finger to Nvidia during a ... - Quora\n"
     ]
    }
   ],
   "source": [
    "# Find by XPATH\n",
    "    # XPATH는 특정 tag pattern으로 찾는다\n",
    "\n",
    "RESULTS_LOCATOR = \"//div/h3/a\"\n",
    "    # 위에 검색한 페이지에서 불러왔다\n",
    "        # F12해서 찾은 후, 그것을 우클릭하면 XPATH를 copy할 수 있다.\n",
    "            # 해당 부분의 전체 XPATH : \"//*[@id=\"rso\"]/div[1]/div/div[1]/div/div/h3/a\"\n",
    "            # 앞은 중요하지 않고, 오히려 index값이 늘어나서 문제가 된다\n",
    "                # 뒤에서부터 공통되는 부분만 필요 : \"//div/h3/a\"\n",
    "WebDriverWait(ff_driver, 10).until(\\\n",
    "    EC.visibility_of_element_located((By.XPATH, RESULTS_LOCATOR)))\n",
    "    # implicitly_wait은 특정 시간만 기다리는 것\n",
    "        # WebDriverWait은 로딩이 다 끝날 때까지 기다리게 만든다\n",
    "page1_results = ff_driver.find_elements(By.XPATH, RESULTS_LOCATOR)\n",
    "    # find_elements_by_xpath == find_elements(By.XPATH)\n",
    "\n",
    "for item in page1_results:\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQLite\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python library's version\n",
    "sqlite3.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.14.2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sqlite3's version\n",
    "sqlite3.sqlite_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
